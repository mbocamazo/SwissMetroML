{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Michael Bocamazo**\n",
    "\n",
    "**Question 3.1**: How well does a 2-stage model perform with logistic regression and minimal feature engineering?\n",
    "\n",
    "**Date**: 2016/11/28\n",
    "\n",
    "**Methods**: Select down to a few features, train multistage model with split on car availability, and cross-validate to find ridge regression term.  Examine resultant weights in both models.  \n",
    "\n",
    "New from previous notebook: Have encapsulated the multi-stage model.\n",
    "\n",
    "**Conclusion**: A multi-stage model with logistic regression can perform better than guessing the most frequent class.  However, it does not predict anything present in the \"TRAIN\" class at all.  The first stage predicts car v. non-car for samples in which CAR is available.  Those predicted not car are then passed into the second stage, with the no car available samples.  The second stage can be multinomial or one-versus-all for all of the classes, not just TRAIN v. SwissMetro, to allow missed samples that should fall in the CAR class to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\", {\"grid.linewidth\": .5, \"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ML_utils as ml_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous question, we have a clean data frame, and a data frame with expanded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_e = pd.read_csv('SM_expand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO', 'LUGGAGE', 'AGE',\n",
       "       'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'CAR_AV', 'TRAIN_TT',\n",
       "       'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'SM_SEATS', 'CAR_TT',\n",
       "       'CAR_CO', 'CHOICE', 'min_CO', 'ratio_TRAIN_CO', 'ratio_SM_CO',\n",
       "       'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT', 'ratio_SM_TT',\n",
       "       'ratio_CAR_TT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to include\n",
    "We can make a simple list of features that would be appropriate for a logistic regression model without any transformations.  The certain ones are the numerics and binary features.  Less certain are the ordinal encoded features.  The simply encoded features require an OHE.\n",
    "\n",
    "The **pure feats** are the numeric features that we expect to get a straight correlation to choice, except for cost, which needs an adjustment based on GA to work well.  \n",
    "\n",
    "The **simple feats** are binary or ordinal encoded features.  The INCOME and AGE features both have a category for unknowns, at the endpoint.  If the latent classes behind the unknowns are equally distributed among the values, this acts as a regularizer.  In both of these features they occupy the greatest value.  They could be made to occupy the the mid value for a cleaner regularization.\n",
    "\n",
    "The **ratio features** are those developed in the first pass to compare between alternatives.  These should be quite useful for random forests, because they condense the number of nodes needed to express the comparison of the cost features.  However, they might not be useful for logistic regression.  We can experiment.\n",
    "\n",
    "Finally, there are 5 non-ordinal **encoded features** that we'll probably omit until we want much higher complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_feats = ['SURVEY','LUGGAGE','INCOME','AGE','GA','SM_SEATS','CAR_AV','FIRST','MALE']\n",
    "pure_feats = ['TRAIN_TT', 'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'CAR_TT','CAR_CO']\n",
    "encode_feats = ['PURPOSE','TICKET','WHO','ORIGIN','DEST']\n",
    "ratio_feats = ['min_CO', 'ratio_TRAIN_CO','ratio_SM_CO', 'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT',\n",
    "               'ratio_SM_TT','ratio_CAR_TT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Logistic Regression\n",
    "Or, \"Multinomial Logit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_e.drop(\"CHOICE\", axis = 1)\n",
    "y = df_e['CHOICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split was chosen based on session-split in q_00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 7002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = ml_ut.tt_split(X,y,split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll take the pure numeric feats and the simple ordinal encodings or binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = pure_feats + simple_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining the accuracy results, we should recall that the classifier needs to do better than about 64% accuracy to beat predicting everything in the dominant class, which is SwissMetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.635961\n",
       "1    0.182519\n",
       "3    0.181520\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()/len(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression No Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.70249302042\n",
      "Training Accuracy: 0.68694658669\n",
      "Testing  Log Loss: 0.787769357819\n",
      "Testing  Accuracy: 0.580844767285\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test using Pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ML_utils as ml_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ML_utils' from '/home/atproofer/SwissMetro/SwissMetroML/ML_utils.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(ml_ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "6456\n",
      "3717\n",
      "2894\n"
     ]
    }
   ],
   "source": [
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model(Xtrain, Xtest, ytrain, ytest, ML_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60554127392173662"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60532687651331718"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very low divergence!  Suggests not fitting closely enough to data.  But the test accuracy did improve by 2% over no pipeline.  This will help us validate the use of random forests with a hard-coded split of car v. no car.  **Not better than guessing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the weights in each model.  The first model is the discrimination between car and not car.  The second model could be the discrimination between Train and SwissMetro if we are completely confident in breaking all of the cars in the first model.  In this model structure, the second step actually does the 3 class discrimination. \n",
    "\n",
    "We applied the standard scaling - zero mean and unit variance to all features, so it is possible to compare the weights more directly.\n",
    "\n",
    "Recall that the following weights are propensity of car choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452455</td>\n",
       "      <td>TRAIN_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032741</td>\n",
       "      <td>TRAIN_CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016610</td>\n",
       "      <td>TRAIN_HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201682</td>\n",
       "      <td>SM_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.358400</td>\n",
       "      <td>SM_CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.026891</td>\n",
       "      <td>SM_HE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.016450</td>\n",
       "      <td>CAR_TT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.336056</td>\n",
       "      <td>CAR_CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.134848</td>\n",
       "      <td>SURVEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.260097</td>\n",
       "      <td>LUGGAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.077895</td>\n",
       "      <td>INCOME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.056995</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.485883</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065427</td>\n",
       "      <td>SM_SEATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>CAR_AV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.026985</td>\n",
       "      <td>FIRST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.060891</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.452455  TRAIN_TT\n",
       "1  -0.032741  TRAIN_CO\n",
       "2   0.016610  TRAIN_HE\n",
       "3   0.201682     SM_TT\n",
       "4   0.358400     SM_CO\n",
       "5   0.026891     SM_HE\n",
       "6  -1.016450    CAR_TT\n",
       "7  -0.336056    CAR_CO\n",
       "8   1.134848    SURVEY\n",
       "9   0.260097   LUGGAGE\n",
       "10  0.077895    INCOME\n",
       "11  0.056995       AGE\n",
       "12 -0.485883        GA\n",
       "13  0.065427  SM_SEATS\n",
       "14  0.000000    CAR_AV\n",
       "15 -0.026985     FIRST\n",
       "16 -0.060891      MALE"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model1.steps[1][1].coef_[0], ML_feat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are where the survey is administered - if the survey was performed on a car trip, it is much more likely to correspond to a car choice. Travel time of car, and of train are both fairly important.  If the user had a GA (yearly ticket), much less likely to choose car.  These weights are overall sensical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the weights in the second model.  It is a one-v-all classification problem, so each choice will have a set of weights that are the propensity of choice of a mode correlated with the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Train Choice</th>\n",
       "      <th>SM Choice</th>\n",
       "      <th>Car Choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_TT</td>\n",
       "      <td>-0.409162</td>\n",
       "      <td>0.178377</td>\n",
       "      <td>0.423155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_CO</td>\n",
       "      <td>-2.007174</td>\n",
       "      <td>1.858261</td>\n",
       "      <td>-0.037233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_HE</td>\n",
       "      <td>-0.290533</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.031135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SM_TT</td>\n",
       "      <td>0.329314</td>\n",
       "      <td>-0.375570</td>\n",
       "      <td>0.331431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SM_CO</td>\n",
       "      <td>1.623101</td>\n",
       "      <td>-1.592022</td>\n",
       "      <td>0.432404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SM_HE</td>\n",
       "      <td>0.103237</td>\n",
       "      <td>-0.073671</td>\n",
       "      <td>0.014438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAR_TT</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.360145</td>\n",
       "      <td>-1.194915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAR_CO</td>\n",
       "      <td>-0.159817</td>\n",
       "      <td>0.269827</td>\n",
       "      <td>-0.409846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>-0.705220</td>\n",
       "      <td>-0.356628</td>\n",
       "      <td>0.969460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LUGGAGE</td>\n",
       "      <td>-0.023662</td>\n",
       "      <td>-0.043234</td>\n",
       "      <td>0.173462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>-0.027304</td>\n",
       "      <td>0.036348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>-0.292101</td>\n",
       "      <td>0.114130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GA</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>-0.559892</td>\n",
       "      <td>-0.604964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SM_SEATS</td>\n",
       "      <td>0.062369</td>\n",
       "      <td>-0.077680</td>\n",
       "      <td>0.082451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAR_AV</td>\n",
       "      <td>-0.290567</td>\n",
       "      <td>-0.218911</td>\n",
       "      <td>2.790637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FIRST</td>\n",
       "      <td>-0.055594</td>\n",
       "      <td>0.071902</td>\n",
       "      <td>-0.070502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MALE</td>\n",
       "      <td>-0.161440</td>\n",
       "      <td>0.155467</td>\n",
       "      <td>-0.054924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Train Choice  SM Choice  Car Choice\n",
       "0   TRAIN_TT     -0.409162   0.178377    0.423155\n",
       "1   TRAIN_CO     -2.007174   1.858261   -0.037233\n",
       "2   TRAIN_HE     -0.290533   0.154255    0.031135\n",
       "3      SM_TT      0.329314  -0.375570    0.331431\n",
       "4      SM_CO      1.623101  -1.592022    0.432404\n",
       "5      SM_HE      0.103237  -0.073671    0.014438\n",
       "6     CAR_TT      0.066243   0.360145   -1.194915\n",
       "7     CAR_CO     -0.159817   0.269827   -0.409846\n",
       "8     SURVEY     -0.705220  -0.356628    0.969460\n",
       "9    LUGGAGE     -0.023662  -0.043234    0.173462\n",
       "10    INCOME      0.033616  -0.027304    0.036348\n",
       "11       AGE      0.360060  -0.292101    0.114130\n",
       "12        GA      0.736847  -0.559892   -0.604964\n",
       "13  SM_SEATS      0.062369  -0.077680    0.082451\n",
       "14    CAR_AV     -0.290567  -0.218911    2.790637\n",
       "15     FIRST     -0.055594   0.071902   -0.070502\n",
       "16      MALE     -0.161440   0.155467   -0.054924"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_weights = pd.DataFrame(list(zip(ML_feat, model2.steps[1][1].coef_[0], model2.steps[1][1].coef_[1], model2.steps[1][1].coef_[2])))\n",
    "model2_weights.columns = ['Feature','Train Choice','SM Choice','Car Choice']\n",
    "model2_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travel time was consistently important, as was cost (but not for CAR).  Survey location, again important correlation with car.  Age surprising - older customers seem to disfavor the new mode of transport.\n",
    "Luggage, income, gender, first class travel, SM seat configuration all fairly unimportant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_feats = ['SURVEY','LUGGAGE','INCOME','AGE','GA','SM_SEATS','CAR_AV','FIRST','MALE']\n",
    "pure_feats = ['TRAIN_TT', 'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'CAR_TT','CAR_CO']\n",
    "encode_feats = ['PURPOSE','TICKET','WHO','ORIGIN','DEST']\n",
    "ratio_feats = ['min_CO', 'ratio_TRAIN_CO','ratio_SM_CO', 'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT',\n",
    "               'ratio_SM_TT','ratio_CAR_TT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the ratio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = simple_feats + pure_feats + ratio_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.676122464949\n",
      "Training Accuracy: 0.706512425021\n",
      "Testing  Log Loss: 0.811695151413\n",
      "Testing  Accuracy: 0.61985472155\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional features give a small increase in testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "6283\n",
      "3717\n",
      "2576\n"
     ]
    }
   ],
   "source": [
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model(Xtrain, Xtest, ytrain, ytest, ML_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62253641816623817"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  67, 1200,   11],\n",
       "       [ 454, 3791,  208],\n",
       "       [ 112,  658,  501]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63976324993274147"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  125,   20],\n",
       "       [   0, 1507,  256],\n",
       "       [   0,  938,  871]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even more so with the test set!  Strange - the training set has lower accuracy than the test, even while predicted no choices of \"TRAIN\" correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, from the distribution of predictions we can't say that it performs much better than random currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include the encoded features\n",
    "It may still include some information, even without expanding into OHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = simple_feats + pure_feats + ratio_feats + encode_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.665511907776\n",
      "Training Accuracy: 0.713081976578\n",
      "Testing  Log Loss: 0.78561370238\n",
      "Testing  Accuracy: 0.638687113263\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the additional features give a small increase in testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "6286\n",
      "3717\n",
      "2425\n"
     ]
    }
   ],
   "source": [
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model(Xtrain, Xtest, ytrain, ytest, ML_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61768066266780919"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  70, 1193,   15],\n",
       "       [ 494, 3755,  204],\n",
       "       [ 116,  655,  500]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66020984665052462"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  128,   17],\n",
       "       [   0, 1463,  300],\n",
       "       [   0,  818,  991]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a pipeline model, we do actually show improvement over random guessing - including not putting any in the \"TRAIN\" class!  This could indicate that the second model could be improved by being multinomial instead of one-versus-all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the multinomial model \n",
    "Within the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ML_utils' from '/home/atproofer/SwissMetro/SwissMetroML/ML_utils.py'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(ml_ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model_multinomial(Xtrain, Xtest, ytrain, ytest, ML_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61496715224221654"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  71, 1188,   19],\n",
       "       [ 513, 3735,  205],\n",
       "       [ 125,  646,  500]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytrain, dy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66182405165456015"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  128,   17],\n",
       "       [   0, 1467,  296],\n",
       "       [   0,  816,  993]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a negligible amount better, but still does not predict anything in the TRAIN class!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
