{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Michael Bocamazo**\n",
    "\n",
    "**Question 4**: How well does a 2-stage model perform with Random Forests and minimal feature engineering?\n",
    "\n",
    "**Date**: 2016/11/28\n",
    "\n",
    "**Methods**: Use the same feature sets, train a multistage model in the same way as the previous notebook, and analyze the random forests generated.\n",
    "\n",
    "The first stage predicts car v. non-car for samples in which CAR is available.  Those predicted not car are then passed into the second stage, with the no car available samples included.  The second stage can be multinomial or one-versus-all for all of the classes, not just TRAIN v. SwissMetro, to allow missed samples that should fall in the CAR class to do so.\n",
    "\n",
    "**Conclusion**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\", {\"grid.linewidth\": .5, \"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ML_utils as ml_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous question, we have a clean data frame, and a data frame with expanded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_e = pd.read_csv('SM_expand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO', 'LUGGAGE', 'AGE',\n",
       "       'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'CAR_AV', 'TRAIN_TT',\n",
       "       'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'SM_SEATS', 'CAR_TT',\n",
       "       'CAR_CO', 'CHOICE', 'min_CO', 'ratio_TRAIN_CO', 'ratio_SM_CO',\n",
       "       'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT', 'ratio_SM_TT',\n",
       "       'ratio_CAR_TT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to include\n",
    "We can make a simple list of features that would be appropriate for a logistic regression model without any transformations.  The certain ones are the numerics and binary features.  Less certain are the ordinal encoded features.  The simply encoded features require an OHE.\n",
    "\n",
    "The **pure feats** are the numeric features that we expect to get a straight correlation to choice, except for cost, which needs an adjustment based on GA to work well.  \n",
    "\n",
    "The **simple feats** are binary or ordinal encoded features.  The INCOME and AGE features both have a category for unknowns, at the endpoint.  If the latent classes behind the unknowns are equally distributed among the values, this acts as a regularizer.  In both of these features they occupy the greatest value.  They could be made to occupy the the mid value for a cleaner regularization.\n",
    "\n",
    "The **ratio features** are those developed in the first pass to compare between alternatives.  These should be quite useful for random forests, because they condense the number of nodes needed to express the comparison of the cost features.  However, they might not be useful for logistic regression.  We can experiment.\n",
    "\n",
    "Finally, there are 5 non-ordinal **encoded features** that we'll probably omit until we want much higher complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_feats = ['SURVEY','LUGGAGE','INCOME','AGE','GA','SM_SEATS','CAR_AV','FIRST','MALE']\n",
    "pure_feats = ['TRAIN_TT', 'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'CAR_TT','CAR_CO']\n",
    "encode_feats = ['PURPOSE','TICKET','WHO','ORIGIN','DEST']\n",
    "ratio_feats = ['min_CO', 'ratio_TRAIN_CO','ratio_SM_CO', 'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT',\n",
    "               'ratio_SM_TT','ratio_CAR_TT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_e.drop(\"CHOICE\", axis = 1)\n",
    "y = df_e['CHOICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split was chosen based on session-split in q_00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 7002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = ml_ut.tt_split(X,y,split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll take the pure numeric feats and the simple ordinal encodings or binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = pure_feats + simple_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining the accuracy results, we should recall that the classifier needs to do better than about 64% accuracy to beat predicting everything in the dominant class, which is SwissMetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.635961\n",
       "1    0.182519\n",
       "3    0.181520\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()/len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.486683\n",
       "2    0.474307\n",
       "1    0.039010\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat bad that this discrepancy was discovered only now, but it might point us in the direction of using a group shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Shuffle all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to shuffle the User IDs, not the samples themselves, so no one person is included in both the train an test sets.  It isn't clear if an equivalent function exists in scikit learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ~11000 samples, within ~1200 responding users who were given different scenarios and then asked their preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10719, step=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_assignments = np.random.permutation(1192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 156,  845,  980, ...,  838, 1063,  563])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rebuilds the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shuffle = pd.concat(list(map(lambda z: df_e[df_e['ID']==z], group_assignments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shuffle.index = (range(len(df_shuffle)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_shuffle.to_csv('SM_shuffle.csv',delimiter = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_e = df_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examining this section shows that this split is again appropriate\n",
    "# df_e.iloc[7000:7010]\n",
    "split = 7002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_e.drop(\"CHOICE\", axis = 1)\n",
    "y = df_e['CHOICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = ml_ut.tt_split(X,y,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.584690\n",
       "3    0.280777\n",
       "1    0.134533\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()/len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.571197\n",
       "3    0.299083\n",
       "1    0.129720\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are much more evenly distributed in each set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Logistic Regression\n",
    "Repeat the tests - shuffling the data may have made a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = pure_feats + simple_feats + encode_feats + ratio_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.675518645067\n",
      "Training Accuracy: 0.701228220508\n",
      "Testing  Log Loss: 0.717972234424\n",
      "Testing  Accuracy: 0.685814455232\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than predicting the dominant class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 144,  314,   23],\n",
       "       [  90, 1742,  286],\n",
       "       [   4,  448,  657]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, model.predict(Xtest[ML_feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Train Choice</th>\n",
       "      <th>SM Choice</th>\n",
       "      <th>Car Choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_TT</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>0.002585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_CO</td>\n",
       "      <td>-0.002321</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>-0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_HE</td>\n",
       "      <td>-0.008416</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>-0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SM_TT</td>\n",
       "      <td>-0.026267</td>\n",
       "      <td>0.012685</td>\n",
       "      <td>-0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SM_CO</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SM_HE</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>-0.006416</td>\n",
       "      <td>-0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAR_TT</td>\n",
       "      <td>-0.002707</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>-0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAR_CO</td>\n",
       "      <td>-0.005873</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>-1.241467</td>\n",
       "      <td>-1.456547</td>\n",
       "      <td>2.929160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LUGGAGE</td>\n",
       "      <td>-0.124960</td>\n",
       "      <td>-0.151437</td>\n",
       "      <td>0.379516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>-0.081163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.351587</td>\n",
       "      <td>-0.275183</td>\n",
       "      <td>0.153154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GA</td>\n",
       "      <td>1.070227</td>\n",
       "      <td>-0.230405</td>\n",
       "      <td>-1.227989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SM_SEATS</td>\n",
       "      <td>0.180426</td>\n",
       "      <td>-0.207970</td>\n",
       "      <td>0.074184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAR_AV</td>\n",
       "      <td>-1.396980</td>\n",
       "      <td>-1.576302</td>\n",
       "      <td>4.597469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FIRST</td>\n",
       "      <td>-0.194066</td>\n",
       "      <td>-0.129937</td>\n",
       "      <td>0.295995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MALE</td>\n",
       "      <td>-0.137537</td>\n",
       "      <td>0.122183</td>\n",
       "      <td>-0.036790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PURPOSE</td>\n",
       "      <td>0.144801</td>\n",
       "      <td>-0.148160</td>\n",
       "      <td>0.115893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TICKET</td>\n",
       "      <td>0.091839</td>\n",
       "      <td>-0.215587</td>\n",
       "      <td>0.269080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WHO</td>\n",
       "      <td>-0.336811</td>\n",
       "      <td>0.209151</td>\n",
       "      <td>-0.166332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>-0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DEST</td>\n",
       "      <td>-0.013938</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>min_CO</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.007899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ratio_TRAIN_CO</td>\n",
       "      <td>0.051651</td>\n",
       "      <td>-0.044838</td>\n",
       "      <td>-0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ratio_SM_CO</td>\n",
       "      <td>-0.041275</td>\n",
       "      <td>0.033834</td>\n",
       "      <td>0.018786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ratio_CAR_CO</td>\n",
       "      <td>0.362208</td>\n",
       "      <td>0.363903</td>\n",
       "      <td>-1.248710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>min_TT</td>\n",
       "      <td>0.023087</td>\n",
       "      <td>-0.015066</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ratio_TRAIN_TT</td>\n",
       "      <td>-0.726243</td>\n",
       "      <td>0.248307</td>\n",
       "      <td>0.302553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ratio_SM_TT</td>\n",
       "      <td>0.157512</td>\n",
       "      <td>-2.015696</td>\n",
       "      <td>0.147664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ratio_CAR_TT</td>\n",
       "      <td>0.481755</td>\n",
       "      <td>0.160589</td>\n",
       "      <td>-0.776831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  Train Choice  SM Choice  Car Choice\n",
       "0         TRAIN_TT      0.001287  -0.003544    0.002585\n",
       "1         TRAIN_CO     -0.002321   0.002365   -0.000168\n",
       "2         TRAIN_HE     -0.008416   0.003967   -0.000970\n",
       "3            SM_TT     -0.026267   0.012685   -0.003787\n",
       "4            SM_CO      0.001767  -0.001716    0.000104\n",
       "5            SM_HE      0.013411  -0.006416   -0.000857\n",
       "6           CAR_TT     -0.002707   0.005695   -0.005434\n",
       "7           CAR_CO     -0.005873   0.006290    0.000944\n",
       "8           SURVEY     -1.241467  -1.456547    2.929160\n",
       "9          LUGGAGE     -0.124960  -0.151437    0.379516\n",
       "10          INCOME     -0.008837   0.056647   -0.081163\n",
       "11             AGE      0.351587  -0.275183    0.153154\n",
       "12              GA      1.070227  -0.230405   -1.227989\n",
       "13        SM_SEATS      0.180426  -0.207970    0.074184\n",
       "14          CAR_AV     -1.396980  -1.576302    4.597469\n",
       "15           FIRST     -0.194066  -0.129937    0.295995\n",
       "16            MALE     -0.137537   0.122183   -0.036790\n",
       "17         PURPOSE      0.144801  -0.148160    0.115893\n",
       "18          TICKET      0.091839  -0.215587    0.269080\n",
       "19             WHO     -0.336811   0.209151   -0.166332\n",
       "20          ORIGIN     -0.004988   0.005817   -0.001728\n",
       "21            DEST     -0.013938   0.004843    0.000903\n",
       "22          min_CO     -0.000102  -0.000135   -0.007899\n",
       "23  ratio_TRAIN_CO      0.051651  -0.044838   -0.022938\n",
       "24     ratio_SM_CO     -0.041275   0.033834    0.018786\n",
       "25    ratio_CAR_CO      0.362208   0.363903   -1.248710\n",
       "26          min_TT      0.023087  -0.015066    0.007207\n",
       "27  ratio_TRAIN_TT     -0.726243   0.248307    0.302553\n",
       "28     ratio_SM_TT      0.157512  -2.015696    0.147664\n",
       "29    ratio_CAR_TT      0.481755   0.160589   -0.776831"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_weights = pd.DataFrame(list(zip(ML_feat, model.coef_[0], model.coef_[1], model.coef_[2])))\n",
    "model2_weights.columns = ['Feature','Train Choice','SM Choice','Car Choice']\n",
    "model2_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiStage Logistic Regression\n",
    "Repeat the previous multistage logistic regression tests with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model(Xtrain, Xtest, ytrain, ytest, ML_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64859762675296651"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  41,  419,   21],\n",
       "       [ 159, 1719,  240],\n",
       "       [  45,  419,  645]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simpler model actually performed better when the class split was more even"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Random Forest\n",
    "Without a multistage approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = pure_feats + simple_feats + ratio_feats + encode_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(max_depth = 12, n_estimators=1000).fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.308707568319\n",
      "Training Accuracy: 0.927306483862\n",
      "Testing  Log Loss: 0.661010921949\n",
      "Testing  Accuracy: 0.710355987055\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than the logistic regression.  Picked the max_depth based on past experience of other data sets with a similar number of features.  However, it could be cross validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 162,  284,   35],\n",
       "       [ 114, 1771,  233],\n",
       "       [  18,  495,  596]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, model.predict(Xtest[ML_feat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiStage Random Forest\n",
    "\n",
    "Here we force the random forest to take car availability as a first node.  Hypothesized Benefits: it picks the useful information out automatically.  Possible negatives: less training data to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = ensemble.RandomForestClassifier(max_depth = 12, n_estimators = 1000)\n",
    "clf2 = ensemble.RandomForestClassifier(max_depth = 12, n_estimators = 1000)\n",
    "model1, model2, dy_train, dy_test = ml_ut.multistage_model_gen(Xtrain, Xtest, ytrain, ytest, ML_feat, clf1, clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65507011866235165"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  32,  437,   12],\n",
       "       [ 140, 1783,  195],\n",
       "       [  46,  449,  614]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, dy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multistage did not help in either case.  But it was an interesting thought to try.  The weights of the logistic regression model showed that the CAR_AV feature was very important, as expected, and looking at the feature importance in both of these Random Forest models will probably show the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
