{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Michael Bocamazo**\n",
    "\n",
    "**Question 3**: How well does a 2-stage model perform with logistic regression and minimal feature engineering?\n",
    "\n",
    "**Date**: 2016/11/27\n",
    "\n",
    "**Methods**: Select down to a few features, train multistage model with split on car availability, and cross-validate to find ridge regression term.  Examine resultant weights in both models.\n",
    "\n",
    "**Conclusion**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\", {\"grid.linewidth\": .5, \"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ML_utils as ml_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous question, we have a clean data frame, and a data frame with expanded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('SM_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO', 'LUGGAGE', 'AGE',\n",
       "       'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'CAR_AV', 'TRAIN_TT',\n",
       "       'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'SM_SEATS', 'CAR_TT',\n",
       "       'CAR_CO', 'CHOICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_e = pd.read_csv('SM_expand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO', 'LUGGAGE', 'AGE',\n",
       "       'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'CAR_AV', 'TRAIN_TT',\n",
       "       'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'SM_SEATS', 'CAR_TT',\n",
       "       'CAR_CO', 'CHOICE', 'min_CO', 'ratio_TRAIN_CO', 'ratio_SM_CO',\n",
       "       'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT', 'ratio_SM_TT',\n",
       "       'ratio_CAR_TT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to include\n",
    "We can make a simple list of features that would be appropriate for a logistic regression model without any transformations.  The certain ones are the numerics and binary features.  Less certain are the ordinal encoded features.  The simply encoded features require an OHE.\n",
    "\n",
    "The **pure feats** are the numeric features that we expect to get a straight correlation to choice, except for cost, which needs an adjustment based on GA to work well.  \n",
    "\n",
    "The **simple feats** are binary or ordinal encoded features.  The INCOME and AGE features both have a category for unknowns, at the endpoint.  If the latent classes behind the unknowns are equally distributed among the values, this acts as a regularizer.  In both of these features they occupy the greatest value.  They could be made to occupy the the mid value for a cleaner regularization.\n",
    "\n",
    "The **ratio features** are those developed in the first pass to compare between alternatives.  These should be quite useful for random forests, because they condense the number of nodes needed to express the comparison of the cost features.  However, they might not be useful for logistic regression.  We can experiment.\n",
    "\n",
    "Finally, there are 5 non-ordinal **encoded features** that we'll probably omit until we want much higher complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_feats = ['SURVEY','LUGGAGE','INCOME','AGE','GA','SM_SEATS','CAR_AV','FIRST','MALE']\n",
    "pure_feats = ['TRAIN_TT', 'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'CAR_TT','CAR_CO']\n",
    "encode_feats = ['PURPOSE','TICKET','WHO','ORIGIN','DEST']\n",
    "ratio_feats = ['min_CO', 'ratio_TRAIN_CO','ratio_SM_CO', 'ratio_CAR_CO', 'min_TT', 'ratio_TRAIN_TT',\n",
    "               'ratio_SM_TT','ratio_CAR_TT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Logistic Regression\n",
    "Or, \"Multinomial Logit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_e.drop(\"CHOICE\", axis = 1)\n",
    "y = df_e['CHOICE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split was chosen based on session-split in q_00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 7002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = ml_ut.tt_split(X,y,split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll take the pure numeric feats and the simple ordinal encodings or binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_feat = pure_feats + simple_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_car_av = Xtrain[Xtrain['CAR_AV']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_car_av_index = Xtrain['CAR_AV']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain_car_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the respondents in the chosen training set have a car available.  But it is important for the ~20% that do not that they have a different model, and are not mixed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain_car_av = ytrain[Xtrain_car_av_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3414\n",
       "3    1271\n",
       "1     634\n",
       "Name: CHOICE, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_car_av.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOICE 1,2,3 = Train, SM, Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4453\n",
       "1    1278\n",
       "3    1271\n",
       "Name: CHOICE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that there are no car choices where it is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrain_car_non = ytrain_car_av == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "clf = LogisticRegression()\n",
    "model = sklearn.pipeline.Pipeline([('scaler',scaler),('LogReg',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LogReg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain_car_av[ML_feat], ytrain_car_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy_x = model.predict(Xtrain_car_av[ML_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the argument, let's look at the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79375822523030648"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain_car_non, dy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent test set would be those in which a car is available; predict car-non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest_car_av = Xtest[Xtest['CAR_AV']==1]\n",
    "ytest_car_non = ytest[Xtest['CAR_AV']==1]==3 # this indexes into the CAR_AV examples\n",
    "# and checks if the chosen mode is CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy_x_test = model.predict(Xtest_car_av[ML_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62389023405972555"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest_car_non, dy_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1702,  206],\n",
       "       [1192,  617]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest_car_non, dy_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertical is true label, horizontal is predicted label.  The prediction skews too heavily towards not car choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.513317\n",
       "True     0.486683\n",
       "Name: CHOICE, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_car_non.value_counts()/len(ytest_car_non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the model has some discriminative power.  However, we are probably looking for something much better - this is only the first part of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot include the breakout into multiple subsets in the pipeline because they are not proper 'transforms' - they do not preserve the shape of the data.  So we need to write it in a different functional style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_car_av = Xtrain[Xtrain['CAR_AV']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_car_av_index = Xtrain['CAR_AV']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7002"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain_car_av_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_pTR = Xtrain_car_av[~dy_x]\n",
    "\n",
    "ytrain_pTR = ytrain_car_av[~dy_x]\n",
    "\n",
    "Xtrain_no_car = Xtrain[~Xtrain_car_av_index]\n",
    "\n",
    "ytrain_no_car = ytrain[~Xtrain_car_av_index]\n",
    "\n",
    "Xtr_stage2 = pd.concat([Xtrain_pTR, Xtrain_no_car])\n",
    "ytr_stage2 = pd.concat([ytrain_pTR, ytrain_no_car])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unchanged label vector will include car choices - should this be retained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler2 = sklearn.preprocessing.StandardScaler()\n",
    "clf2 = LogisticRegression()\n",
    "model2 = sklearn.pipeline.Pipeline([('scaler',scaler2),('LogReg',clf2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LogReg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(Xtr_stage2[ML_feat], ytr_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy_x2 = model2.predict(Xtr_stage2[ML_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5783\n",
       "1     626\n",
       "3      47\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dy_x2)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65934065934065933"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrain_car_av[dy_x] == 3)/len(ytrain_car_av[dy_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69665809768637532"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sklearn.metrics.accuracy_score(ytr_stage2, dy_x2)*len(ytr_stage2) + sum(ytrain_car_av[dy_x]==3))/len(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our accuracy score.  But it does not give insight into the failure modes.  Also, it is worse than the previous model in training error.  Want to make the actual label vector for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the same breakout for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest_car_av_index = Xtest['CAR_AV']==1\n",
    "ytest_car_av = ytest[Xtest_car_av_index]\n",
    "\n",
    "Xtest_pTR = Xtest_car_av[~dy_x_test]\n",
    "ytest_pTR = ytest_car_av[~dy_x_test]\n",
    "\n",
    "Xtest_no_car = Xtest[Xtest['CAR_AV']!=1]\n",
    "ytest_no_car = ytest[Xtest['CAR_AV']!=1]\n",
    "\n",
    "Xte_stage2 = pd.concat([Xtest_pTR, Xtest_no_car])\n",
    "\n",
    "yte_stage2 = pd.concat([ytest_pTR, ytest_no_car])\n",
    "\n",
    "dy_x2_test = model2.predict(Xte_stage2[ML_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2747\n",
       "3     147\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dy_x2_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No SwissMetro predictions included, and some cars!  This sequence didn't work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74969623329283108"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytest_car_av[dy_x_test]==3)/len(ytest_car_av[dy_x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than the training set??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60532687651331718"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sklearn.metrics.accuracy_score(yte_stage2, dy_x2_test)*len(yte_stage2)+sum(ytest_car_av[dy_x_test]==3))/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model performed much worse.  I wonder if the transformations, that is, the scalings, are done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7002"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dy_x) + len(dy_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10265087422447829"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dy_x)/len(dy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_label_vec(X, dy_x1, dy_x2):\n",
    "    pointer_1 = 0\n",
    "    pointer_2 = 0\n",
    "    pointer_label = 0\n",
    "    label_vec = np.zeros((len(X),1))\n",
    "    for i in X.index:\n",
    "        if X.loc[i,'CAR_AV'] == 1:\n",
    "            if dy_x1[pointer_1]==1:\n",
    "                label_vec[pointer_label] = 3 # this is the code for CAR\n",
    "            else:\n",
    "                label_vec[pointer_label] = dy_x2[pointer_2]\n",
    "                pointer_2 += 1\n",
    "            pointer_1 += 1\n",
    "        else:\n",
    "            label_vec[pointer_label] = dy_x2[pointer_2]\n",
    "            pointer_2 += 1\n",
    "        pointer_label +=1 \n",
    "    print(pointer_1)\n",
    "    print(pointer_2)\n",
    "    return label_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n",
      "6456\n"
     ]
    }
   ],
   "source": [
    "a = construct_label_vec(Xtrain, dy_x, dy_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60554127392173662"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytrain, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  79, 1179,   20],\n",
       "       [ 445, 3798,  210],\n",
       "       [ 102,  806,  363]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytrain, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3717\n",
      "2894\n"
     ]
    }
   ],
   "source": [
    "b = construct_label_vec(Xtest, dy_x_test, dy_x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60532687651331718"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(ytest, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  114,   31],\n",
       "       [   0, 1537,  226],\n",
       "       [   0, 1096,  713]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(ytest, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       ..., \n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the CAR_AV is true, don't advance the 2nd pointer\n",
    "\n",
    "for every sample in the set\n",
    "if the CAR_AV is true, look at dy_x first\n",
    "    if dy_x is true, label it as true, then advance dy_x\n",
    "    if dy_x is false, label is according to dy_x2, then advance dy_x and dy_x2\n",
    "if CAR_AV is false,\n",
    "    label it according to dy_x2, and advance dy_x2\n",
    "    \n",
    "dy_x advances according to number of CAR_AV\n",
    "dy_x2 advances according to CAR_AV && ~dy_x + ~CAR_AV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Xtrain['CAR_AV']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Xtrain['CAR_AV']!=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4773"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~dy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6456"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~dy_x)+sum(Xtrain['CAR_AV']!=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6456"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dy_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_vec = np.zeros((len(X),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dy_x = model.predict(X_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='ovr').fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(solver = \"lbfgs\", multi_class='multinomial').fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_cv = LogisticRegressionCV(multi_class='ovr').fit(Xtrain[ML_feat], ytrain)\n",
    "clf_cv2 = LogisticRegressionCV(multi_class='multinomial').fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Attribute \"C\\_\" gives the value of the regularizer that is best for each class.  Because the 'refit' parameter is default true for this model, the whole model is refit on all of the training data after finding the best hyperparameter C for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.15443469e+01,   1.00000000e-04,   1.00000000e-04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is due to it being the multinomial case and learning the same parameters for the whole set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35938137,  0.35938137,  0.35938137])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv2.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "We can predict on the whole set and then evaluate on the test and train separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py_x = clf.predict_proba(X[ML_feat])\n",
    "dy_x = clf.predict(X[ML_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.699283805597\n",
      "Training Accuracy: 0.69165952585\n",
      "Testing  Log Loss: 0.784816724333\n",
      "Testing  Accuracy: 0.585687382298\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], clf, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is substantially higher on the training set, which is somewhat surprising. Logistic Regression is not something that I think usually overfits.  Let's look at the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.815291533847\n",
      "Training Accuracy: 0.651242502142\n",
      "Testing  Log Loss: 0.962744442308\n",
      "Testing  Accuracy: 0.478611783697\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], clf2, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the multinomial fit was worse than the one-versus-all method for the non-cross-validated case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.787363181432\n",
      "Training Accuracy: 0.657812053699\n",
      "Testing  Log Loss: 0.942837909585\n",
      "Testing  Accuracy: 0.478880817864\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], clf_cv, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.806953372192\n",
      "Training Accuracy: 0.651242502142\n",
      "Testing  Log Loss: 0.953894843485\n",
      "Testing  Accuracy: 0.477804681195\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], clf_cv2, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we do substantially better without the cross-validation.  Perhaps there is another setting that I am overlooking. I did see that the best C values were at the bounds of the search space, which could mean that the bounds need to be widened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase bounds of C parameter\n",
    "The best performing was the dead-simplest.  Let's try to increase the bounds on the C parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.1,    1. ,   10. ,  100. ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = np.logspace(-10,2,13)).fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.802159414805\n",
      "Training Accuracy: 0.659097400743\n",
      "Testing  Log Loss: 1.00768252553\n",
      "Testing  Accuracy: 0.474307237019\n"
     ]
    }
   ],
   "source": [
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+01,   1.00000000e-06,   1.00000000e-10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.699283805597\n",
      "Training Accuracy: 0.69165952585\n",
      "Testing  Log Loss: 0.784816724333\n",
      "Testing  Accuracy: 0.585687382298\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)\n",
    "ml_ut.print_predict(X[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue of C parameter\n",
    "The regularization parameter is the only real parameter to be tuned for logistic regression, besides possibly the issue of one-vs-all against multinomial.  It is possible that the first models learned with cross validation are **worse with less data**, and so they learn sub-optimal parameters.  That is the only explanation I can think of.  We can move on to the inclusion or exclusion of feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping within Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a larger possible issue of structure within the data, meaning that the order of samples in the data set is actually informative to the result.  If there is such an order, the cross validation will be hurt dramatically.  We could keep the train-test split for the sake of testing robustness to this, but the cross-validation grouping does not need to have this.  The input and ouput vectors must be shuffled together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = copy.deepcopy(X[:split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(Xtrain.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.reindex(shuffle_index)\n",
    "ytrain = ytrain.reindex(shuffle_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the groups should at least not be stuck when doing the cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check here to confirm that the training is working as well as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_predict2(X_ml_train, X_ml_test, model, ytrain, ytest, split):\n",
    "    py_x_tr = model.predict_proba(X_ml_train)\n",
    "    dy_x_tr = model.predict(X_ml_train)\n",
    "    py_x_te = model.predict_proba(X_ml_test)\n",
    "    dy_x_te = model.predict(X_ml_test)\n",
    "    print(\"Training Log Loss: \" + str(sklearn.metrics.log_loss(ytrain, py_x_tr)))\n",
    "    print(\"Training Accuracy: \" + str(sklearn.metrics.accuracy_score(ytrain, dy_x_tr)))\n",
    "    print(\"Testing  Log Loss: \" + str(sklearn.metrics.log_loss(ytest, py_x_te)))\n",
    "    print(\"Testing  Accuracy: \" + str(sklearn.metrics.accuracy_score(ytest, dy_x_te)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.699158354787\n",
      "Training Accuracy: 0.691373893173\n",
      "Testing  Log Loss: 0.784915488786\n",
      "Testing  Accuracy: 0.584880279796\n"
     ]
    }
   ],
   "source": [
    "print_predict2(Xtrain[ML_feat], Xtest[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now try with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.722908215667\n",
      "Training Accuracy: 0.676092544987\n",
      "Testing  Log Loss: 0.822443493302\n",
      "Testing  Accuracy: 0.540758676352\n"
     ]
    }
   ],
   "source": [
    "print_predict2(Xtrain[ML_feat], Xtest[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+04,   2.78255940e+00,   2.15443469e+01])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps multinomial would improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(multi_class='multinomial').fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss: 0.803006862125\n",
      "Training Accuracy: 0.652670665524\n",
      "Testing  Log Loss: 0.949665233145\n",
      "Testing  Accuracy: 0.476459510358\n"
     ]
    }
   ],
   "source": [
    "print_predict2(Xtrain[ML_feat], Xtest[ML_feat], model, ytrain, ytest, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No better than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21.5443469,  21.5443469,  21.5443469])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does arrive at a parameter estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(Cs = np.logspace(-10,2,13)).fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation conclusion\n",
    "For the purposes of this investigation into Logistic Regression, we can say that cross validation does not improve hyperparameter estimation because of the reduction in available data for each smaller training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances\n",
    "To complete this examination, we should look at the weights learned for each input feature on the simplest case.\n",
    "\n",
    "For the sake of clarity, we will repeat the data loading code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_e.drop(\"CHOICE\", axis = 1)\n",
    "y = df_e['CHOICE']\n",
    "split = 7002\n",
    "Xtrain, Xtest, ytrain, ytest = ml_ut.tt_split(X,y,split)\n",
    "ML_feat = pure_feats + simple_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(Xtrain[ML_feat], ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_weights = model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target has 3 classes, so the coefficients in the one-versus-all case should be different for each possibility.  CHOICE 1,2,3 = Train, SM, Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_TRAIN_choice = pd.DataFrame(list(zip(ML_feat, feat_weights[0])))\n",
    "weights_TRAIN_choice.columns = [\"feats\", \"weights\"]\n",
    "weights_TRAIN_choice[\"abs_val_weights\"] = weights_TRAIN_choice[\"weights\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats</th>\n",
       "      <th>weights</th>\n",
       "      <th>abs_val_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GA</td>\n",
       "      <td>1.647158</td>\n",
       "      <td>1.647158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>-1.560206</td>\n",
       "      <td>1.560206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAR_AV</td>\n",
       "      <td>-0.744071</td>\n",
       "      <td>0.744071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MALE</td>\n",
       "      <td>-0.346381</td>\n",
       "      <td>0.346381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.345024</td>\n",
       "      <td>0.345024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FIRST</td>\n",
       "      <td>-0.144049</td>\n",
       "      <td>0.144049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SM_SEATS</td>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.078802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SM_SEATS</td>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.078802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LUGGAGE</td>\n",
       "      <td>-0.059824</td>\n",
       "      <td>0.059824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.032924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SM_HE</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.012172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_HE</td>\n",
       "      <td>-0.008051</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SM_TT</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.007240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_TT</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>0.006242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAR_CO</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_CO</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SM_CO</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAR_TT</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feats   weights  abs_val_weights\n",
       "13        GA  1.647158         1.647158\n",
       "9     SURVEY -1.560206         1.560206\n",
       "15    CAR_AV -0.744071         0.744071\n",
       "17      MALE -0.346381         0.346381\n",
       "12       AGE  0.345024         0.345024\n",
       "16     FIRST -0.144049         0.144049\n",
       "6   SM_SEATS  0.078802         0.078802\n",
       "14  SM_SEATS  0.078802         0.078802\n",
       "10   LUGGAGE -0.059824         0.059824\n",
       "11    INCOME  0.032924         0.032924\n",
       "5      SM_HE  0.012172         0.012172\n",
       "2   TRAIN_HE -0.008051         0.008051\n",
       "3      SM_TT  0.007240         0.007240\n",
       "0   TRAIN_TT -0.006242         0.006242\n",
       "8     CAR_CO -0.002323         0.002323\n",
       "1   TRAIN_CO -0.001566         0.001566\n",
       "4      SM_CO  0.000984         0.000984\n",
       "7     CAR_TT  0.000979         0.000979"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_TRAIN_choice.sort_values(by = \"abs_val_weights\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization is necessary\n",
    "Should have thought of this before - the regularization parameter probably isn't very useful, even, when ranges of the input features are so disparate.  Examining the weights learned is not informative when there are some binary features and some pure numeric features.  Looking at the weights also shows that a broken-out model could be very useful.  The SURVEY and CAR_AV feats are very important because they encode where the survey happens and if a car is available at all.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are to do the following:\n",
    "\n",
    "Start with a normalization.\n",
    "\n",
    "Break into two separate models:\n",
    "\n",
    "Car v. no car\n",
    "\n",
    "Of those predicted no car, plus those without car, predict TRAIN v. SM.  All these predictions aggregate and are evaluated against test set.  These are two logistic regression models.\n",
    "\n",
    "Rerun the cross-validation for choosing the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'classes_': array([1, 2, 3]),\n",
       " 'coef_': array([[ -6.24196659e-03,  -1.56614335e-03,  -8.05115379e-03,\n",
       "           7.24015906e-03,   9.84411207e-04,   1.21715247e-02,\n",
       "           7.88019723e-02,   9.78567751e-04,  -2.32301360e-03,\n",
       "          -1.56020575e+00,  -5.98237316e-02,   3.29235890e-02,\n",
       "           3.45024209e-01,   1.64715805e+00,   7.88019723e-02,\n",
       "          -7.44071117e-01,  -1.44049453e-01,  -3.46380749e-01],\n",
       "        [  2.03824369e-03,   1.39944301e-03,   4.05240861e-03,\n",
       "          -8.09453176e-03,  -9.66416735e-04,  -8.71912154e-03,\n",
       "          -9.24285666e-02,   5.30383823e-03,   5.37788114e-03,\n",
       "          -1.06404551e+00,  -1.58561803e-01,  -5.00998228e-02,\n",
       "          -2.52697314e-01,  -1.04758297e+00,  -9.24285666e-02,\n",
       "          -6.51870437e-01,   1.58652484e-01,   3.51000813e-01],\n",
       "        [  4.44609225e-03,  -1.30528340e-04,  -2.19165814e-04,\n",
       "           4.56986448e-03,   2.24049026e-04,  -3.57221475e-04,\n",
       "           5.29144416e-02,  -1.17170580e-02,  -5.68221995e-03,\n",
       "           2.21474243e+00,   3.68628999e-01,   6.36411953e-02,\n",
       "           2.64616295e-02,  -1.09034278e+00,   5.29144416e-02,\n",
       "           3.99785155e+00,  -5.86289009e-02,  -1.72030380e-01]]),\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_': array([-0.94304392,  1.69064806, -5.98624949]),\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_iter_': array([45], dtype=int32),\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
