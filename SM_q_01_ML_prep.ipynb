{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Michael Bocamazo**\n",
    "\n",
    "**Question 1**: Can we transform the given data into the format(s) necessary for a quality machine learning test?  The exploration is already given in the previous notebook.\n",
    "\n",
    "**Date**: 2016/10/12\n",
    "\n",
    "**Methods**: Remove unnecessary data, rescale and preprocess, find relevant forms for the outputs.\n",
    "\n",
    "**Conclusion**: The GA feature is very important and may require a transformation of the cost.  Several features, such as the Origin, Destination, Trip Purpose, and kind of Ticket will likely require an OHE of the top 5 values.  The unnecessary columns and rows were removed.  Keeping it a multiclass problem is probably best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\", {\"grid.linewidth\": .5, \"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ML_utils as ml_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from a csv into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('swissmetro.dat', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SURVEY</th>\n",
       "      <th>SP</th>\n",
       "      <th>ID</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>FIRST</th>\n",
       "      <th>TICKET</th>\n",
       "      <th>WHO</th>\n",
       "      <th>LUGGAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN_TT</th>\n",
       "      <th>TRAIN_CO</th>\n",
       "      <th>TRAIN_HE</th>\n",
       "      <th>SM_TT</th>\n",
       "      <th>SM_CO</th>\n",
       "      <th>SM_HE</th>\n",
       "      <th>SM_SEATS</th>\n",
       "      <th>CAR_TT</th>\n",
       "      <th>CAR_CO</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.0</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "      <td>10728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.630034</td>\n",
       "      <td>0.630034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>596.500000</td>\n",
       "      <td>2.914430</td>\n",
       "      <td>0.470638</td>\n",
       "      <td>2.888423</td>\n",
       "      <td>1.493289</td>\n",
       "      <td>0.678691</td>\n",
       "      <td>2.898490</td>\n",
       "      <td>...</td>\n",
       "      <td>166.626025</td>\n",
       "      <td>514.335477</td>\n",
       "      <td>70.100671</td>\n",
       "      <td>87.466350</td>\n",
       "      <td>670.340697</td>\n",
       "      <td>20.020507</td>\n",
       "      <td>0.118568</td>\n",
       "      <td>123.795209</td>\n",
       "      <td>78.742077</td>\n",
       "      <td>2.152778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.482818</td>\n",
       "      <td>0.482818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344.116678</td>\n",
       "      <td>1.147443</td>\n",
       "      <td>0.499160</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>0.708293</td>\n",
       "      <td>0.603388</td>\n",
       "      <td>1.031726</td>\n",
       "      <td>...</td>\n",
       "      <td>77.353284</td>\n",
       "      <td>1088.931881</td>\n",
       "      <td>37.431633</td>\n",
       "      <td>53.550371</td>\n",
       "      <td>1441.594614</td>\n",
       "      <td>8.161895</td>\n",
       "      <td>0.323295</td>\n",
       "      <td>88.710743</td>\n",
       "      <td>55.263663</td>\n",
       "      <td>0.632293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>596.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>894.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1049.000000</td>\n",
       "      <td>5040.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>796.000000</td>\n",
       "      <td>6720.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GROUP        SURVEY       SP            ID       PURPOSE  \\\n",
       "count  10728.000000  10728.000000  10728.0  10728.000000  10728.000000   \n",
       "mean       2.630034      0.630034      1.0    596.500000      2.914430   \n",
       "std        0.482818      0.482818      0.0    344.116678      1.147443   \n",
       "min        2.000000      0.000000      1.0      1.000000      1.000000   \n",
       "25%        2.000000      0.000000      1.0    298.750000      2.000000   \n",
       "50%        3.000000      1.000000      1.0    596.500000      3.000000   \n",
       "75%        3.000000      1.000000      1.0    894.250000      3.250000   \n",
       "max        3.000000      1.000000      1.0   1192.000000      9.000000   \n",
       "\n",
       "              FIRST        TICKET           WHO       LUGGAGE           AGE  \\\n",
       "count  10728.000000  10728.000000  10728.000000  10728.000000  10728.000000   \n",
       "mean       0.470638      2.888423      1.493289      0.678691      2.898490   \n",
       "std        0.499160      2.191100      0.708293      0.603388      1.031726   \n",
       "min        0.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "25%        0.000000      1.000000      1.000000      0.000000      2.000000   \n",
       "50%        0.000000      3.000000      1.000000      1.000000      3.000000   \n",
       "75%        1.000000      3.000000      2.000000      1.000000      4.000000   \n",
       "max        1.000000     10.000000      3.000000      3.000000      6.000000   \n",
       "\n",
       "           ...           TRAIN_TT      TRAIN_CO      TRAIN_HE         SM_TT  \\\n",
       "count      ...       10728.000000  10728.000000  10728.000000  10728.000000   \n",
       "mean       ...         166.626025    514.335477     70.100671     87.466350   \n",
       "std        ...          77.353284   1088.931881     37.431633     53.550371   \n",
       "min        ...          31.000000      4.000000     30.000000      8.000000   \n",
       "25%        ...         109.000000     58.000000     30.000000     55.000000   \n",
       "50%        ...         157.000000     94.000000     60.000000     78.000000   \n",
       "75%        ...         209.000000    170.000000    120.000000    109.000000   \n",
       "max        ...        1049.000000   5040.000000    120.000000    796.000000   \n",
       "\n",
       "              SM_CO         SM_HE      SM_SEATS        CAR_TT        CAR_CO  \\\n",
       "count  10728.000000  10728.000000  10728.000000  10728.000000  10728.000000   \n",
       "mean     670.340697     20.020507      0.118568    123.795209     78.742077   \n",
       "std     1441.594614      8.161895      0.323295     88.710743     55.263663   \n",
       "min        6.000000     10.000000      0.000000      0.000000      0.000000   \n",
       "25%       70.000000     10.000000      0.000000     70.000000     40.000000   \n",
       "50%      111.000000     20.000000      0.000000    120.000000     76.000000   \n",
       "75%      209.000000     30.000000      0.000000    176.000000    112.000000   \n",
       "max     6720.000000     30.000000      1.000000   1560.000000    520.000000   \n",
       "\n",
       "             CHOICE  \n",
       "count  10728.000000  \n",
       "mean       2.152778  \n",
       "std        0.632293  \n",
       "min        0.000000  \n",
       "25%        2.000000  \n",
       "50%        2.000000  \n",
       "75%        3.000000  \n",
       "max        3.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to drop\n",
    "We'll make a list of the column headers that we want to drop.  Some of the data is uninformative or redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GROUP', 'SURVEY', 'SP', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO',\n",
       "       'LUGGAGE', 'AGE', 'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'TRAIN_AV',\n",
       "       'CAR_AV', 'SM_AV', 'TRAIN_TT', 'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO',\n",
       "       'SM_HE', 'SM_SEATS', 'CAR_TT', 'CAR_CO', 'CHOICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know the meaningful data breakdown in each feature.  The 'GROUP' feature is equivalent to the 'SURVEY' feature, which encodes survey conducted in train (0) or on car trip (1).  These show the equilavence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6759\n",
       "2    3969\n",
       "Name: GROUP, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3969\n",
       "Name: SURVEY, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['GROUP']==2]['SURVEY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6759\n",
       "Name: SURVEY, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['GROUP']==3]['SURVEY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols += ['GROUP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'TRAIN_AV' and 'SM_AV' features are not informative - always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10728\n",
       "Name: TRAIN_AV, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['TRAIN_AV'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10728\n",
       "Name: SM_AV, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['SM_AV'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols += ['TRAIN_AV', 'SM_AV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the 'CAR_AV' is meaningful, and different from where the survey was taken.  It encodes if the car is a possible output, so could be used for segmenting a modeling into two.  The only issue is sharing learning or weights between models, or tree subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9045\n",
       "0    1683\n",
       "Name: CAR_AV, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['CAR_AV'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'SP' simply means stated preference survey, is fixed at 1, and so can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10728\n",
       "Name: SP, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['SP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cols += ['SP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex of the traveller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8046\n",
       "0    2682\n",
       "Name: MALE, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['MALE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class of travel, within a train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5679\n",
       "1    5049\n",
       "Name: FIRST, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['FIRST'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the class of the traveller is still encoded if the survey is given based on a car trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3726\n",
       "0    3033\n",
       "Name: FIRST, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['SURVEY']==1]['FIRST'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GROUP', 'TRAIN_AV', 'SM_AV', 'SP']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in drop_cols:\n",
    "    df1.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SURVEY', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO', 'LUGGAGE', 'AGE',\n",
       "       'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST', 'CAR_AV', 'TRAIN_TT',\n",
       "       'TRAIN_CO', 'TRAIN_HE', 'SM_TT', 'SM_CO', 'SM_HE', 'SM_SEATS', 'CAR_TT',\n",
       "       'CAR_CO', 'CHOICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Remaining Features\n",
    "Let's give a prose description of all the features that haven't yet been referenced.  **SURVEY** is the type of trip, train or car, for which the survey was given.  **ID** is the ID of the user - this is the session ID.  There are 1192 different sessions. Every row with the same ID has the same **CHOICE** value.  **PURPOSE** (9 categorical) was the purpose of the trip for which the survey was taken. **TICKET** (11 categorical) is the kind of ticket, round-trip, one-way, half-day, seasonal, etc.  **WHO** (4 categorical) is who pays: unknown, self, employer, half-half.  **LUGGAGE** (3 cat) 0 pieces, 1 piece, 3 several pieces.  **AGE** (6 cat) is an ordinal encoding of age, with greatest val unknown.  **INCOME** (5 cat) ordinal encoding of income level. **GA** - binary for owning an annual ticket. **ORIG** and **DEST** are 26-level cats encoding the region of travel.  They are probably too large to make useful, so while informative, they are unwieldy and could be dropped.  Then we have 3 types of straight numerical features - **TT** = Travel Time, in minutes, for each type, **CO** = cost, and **HE** = Headway or period between trains.  Cost for the car is computed as a fixed cost per unit distance.  Cost for the Train is computed based on the actual fare for an individual trip, or as the cost of the whole year with a GA - this makes the data quite hard to use, because there is a very clear bimodality in the distribution of costs.  The information it encodes isn't actually useful.  We would have to count on different cost thresholds being learnt for the GA/no GA cases.  Finally, **SM_SEATS** is a binary for the kinds of seats used on the Swiss Metro - airline style, or not.\n",
    "\n",
    "The numerical features we probably want to keep, and we can hypothesize that they will be quite useful in choice prediction.  The origin and destination features probably have to be dropped.  Or, only keep the most frequent 5 or so values.  Purpose and Ticket might be useful, but are still fairly large for a one-hot encoding given how many samples there are.  The ordinal categorical features could be useful, but often have codings for 'unknown' that are at an extreme and so would hurt any linear model.  They could be treated as NAs and then just be sampled from the known distribution.  However, it is probably necessary to A/B test these kinds of data-filling changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Levels of Data\n",
    "We could make several data sets: one with all of the features except for the truly unnecessary or redundant, and another, made beforehand for simplicity without the less likely features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.to_csv('SM_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transformations, we can make another saved set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Target\n",
    "On the CHOICE value.  This probably makes sense to keep as a multioutput problem.  For every row for each ID, there is a different set of Travel Time, Costs, Headway, and other parameters that determine the desirability of each method.  \n",
    "\n",
    "It could however be transformed into a single output problem with session-level accuracy.  So each row could be converted into a set of different alternatives, each with their own travel-related parameters, but with the same customer parameters.  The target would be a binary chosen/not chosen feature.  Then, the output of the model would be a **utility**, rather than a probability, to be **normalized** to get the fractional 'shares allocation' of this user into different alternatives.  This is somewhat complicated by the fact that the different modes aren't easily comparable.  The car mode doesn't have a headway feature, and only SM has different seat configurations.  This generates about 3x the data, but a multioutput problem naturally creates models for each output.  \n",
    "\n",
    "**Different Style**\n",
    "It may be useful to train two different models: one to predict car v. not car, all car-user data goes here, then train v. SM, to which all train-only and car but train/SM choice data goes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1192 different individuals labelling their preferences, at 10728 total combinations of alternatives presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df1['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10728"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some possible appropriate machine learning feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_feat = ['SURVEY','FIRST','LUGGAGE','AGE','MALE','INCOME','GA','CAR_AV','TRAIN_TT',\n",
    "          'TRAIN_CO','TRAIN_HE','SM_TT','SM_CO','SM_HE','SM_SEATS','CAR_TT','CAR_CO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_feat = ['SURVEY','AGE','INCOME','GA','CAR_AV','TRAIN_TT',\n",
    "          'TRAIN_CO','TRAIN_HE','SM_TT','SM_CO','SM_HE','CAR_TT','CAR_CO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_feat = ['CAR_AV','TRAIN_TT','TRAIN_CO','TRAIN_HE','SM_TT','SM_CO','SM_HE','CAR_TT','CAR_CO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Unknown Choice values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is little point in including a class with nine samples in the model, we could add it back in later if strictly necessary for comparison between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k = copy.deepcopy(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k = df_k[df_k['CHOICE']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eliminates nine rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10719"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Minimum Cost\n",
    "We want to be able to create ratio features for the costs, which might improve learning by making direct comparisons.  For all rows, there is a train and SM cost, but there is only a car cost if the user has a car.  So to calculate a valid minimum for ratio features, we must account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_valid_min(df):\n",
    "    x = df1.loc[:,['SM_CO','TRAIN_CO','CAR_CO']].min(axis=1)\n",
    "    for i in range(len(x)):\n",
    "        if x[i]==0:\n",
    "            x[i] = min(df1.loc[i,['SM_CO', 'TRAIN_CO']])\n",
    "    return x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k.loc[:,'min_CO'] = calc_valid_min(df_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_price_feats = ['ratio_TRAIN_CO','ratio_SM_CO','ratio_CAR_CO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k.loc[:,'ratio_TRAIN_CO'] = df_k['TRAIN_CO']/df_k['min_CO']\n",
    "\n",
    "df_k.loc[:,'ratio_SM_CO'] = df_k['SM_CO']/df_k['min_CO']\n",
    "df_k.loc[:,'ratio_CAR_CO'] = df_k['CAR_CO']/df_k['min_CO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Minimum Travel Time\n",
    "Similarly, we want to create a set of travel time ratio features so the comparison can be done directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_valid_min2(df):\n",
    "    x = df1.loc[:,['SM_TT','TRAIN_TT','CAR_TT']].min(axis=1)\n",
    "    for i in range(len(x)):\n",
    "        if x[i]==0:\n",
    "            x[i] = min(df1.loc[i,['SM_TT', 'TRAIN_TT']])\n",
    "    return x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k.loc[:,'min_TT'] = calc_valid_min2(df_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k.loc[:,'ratio_TRAIN_TT'] = df_k['TRAIN_TT']/df_k['min_TT']\n",
    "df_k.loc[:,'ratio_SM_TT'] = df_k['SM_TT']/df_k['min_TT']\n",
    "df_k.loc[:,'ratio_CAR_TT'] = df_k['CAR_TT']/df_k['min_TT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_feats = ratio_price_feats + ['ratio_TRAIN_TT','ratio_SM_TT','ratio_CAR_TT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_feat = ['SURVEY','FIRST','LUGGAGE','AGE','MALE','INCOME','GA','CAR_AV','TRAIN_TT',\n",
    "          'TRAIN_CO','TRAIN_HE','SM_TT','SM_CO','SM_HE','SM_SEATS','CAR_TT','CAR_CO'] + ratio_feats\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result\n",
    "We'll save these likely transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_k.to_csv('SM_expand.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
